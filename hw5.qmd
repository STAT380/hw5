---
title: "Homework 5"
author: "[Diana Batista Capellan]{style='background-color: yellow;'}"
toc: true
title-block-banner: true
title-block-style: default
execute: 
  freeze: true
  cache: true
format:
  #html: # comment this line to get pdf
  pdf: 
    fig-width: 7
    fig-height: 7
editor: 
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------

::: {.callout-important style="font-size: 0.8em;"}
Please read the instructions carefully before submitting your
assignment.

1.  This assignment requires you to only upload a `PDF` file on Canvas
2.  Don't collapse any code cells before submitting.
3.  Remember to make sure all your code output is rendered properly
    before uploading your submission.

⚠️ Please add your name to the author information in the frontmatter
before submitting your assignment ⚠️
:::

In this assignment, we will explore decision trees, support vector
machines and neural networks for classification and regression. The
assignment is designed to test your ability to fit and analyze these
models with different configurations and compare their performance.

We will need the following packages:

```{R, message=FALSE, warning=FALSE, results='hide'}
packages <- c(
  "tibble",
  "dplyr", 
  "readr", 
  "tidyr", 
  "purrr", 
  "broom",
  "magrittr",
  "corrplot",
  "caret",
  "rpart",
  "rpart.plot",
  "e1071",
  "torch", 
  "luz"
)

#renv::install(packages)
sapply(packages, require, character.only=T)
```

## <br><br><br><br>

## Question 1

::: callout-tip
## 60 points

Prediction of Median House prices
:::

###### 1.1 (2.5 points)

The `data` folder contains the `housing.csv` dataset which contains
housing prices in California from the 1990 California census. The
objective is to predict the median house price for California districts
based on various features.

Read the data file as a tibble in R. Preprocess the data such that:

1.  the variables are of the right data type, e.g., categorical
    variables are encoded as factors
2.  all column names to lower case for consistency
3.  Any observations with missing values are dropped

```{R}
path <- "data/housing.csv"

df <- read_csv(path) %>%
  # Convert categorical variables to factors
  mutate_at(vars(ocean_proximity), factor) %>%
  # Convert column names to lowercase
  rename_all(tolower) %>%
  # Remove observations with missing values
  na.omit()

head(df) # Insert your code here
```

------------------------------------------------------------------------

###### 1.2 (2.5 points)

Visualize the correlation matrix of all numeric columns in `df` using
`corrplot()`

```{R}
df %>% select_if(is.numeric) %>%
  cor() %>%
  corrplot(method = "color") # Insert your code here
```

------------------------------------------------------------------------

###### 1.3 (5 points)

Split the data `df` into `df_train` and `df_split` using `test_ind` in
the code below:

```{r}
set.seed(42)
test_ind <- sample(
  1:nrow(df), 
  floor( nrow(df)/10 ),
  replace=FALSE
)

df_train <- df[-test_ind, ] # Insert your code here
df_test  <- df[test_ind, ] # Insert your code here
```

------------------------------------------------------------------------

###### 1.4 (5 points)

Fit a linear regression model to predict the `median_house_value` :

-   `latitude`
-   `longitude`
-   `housing_median_age`
-   `total_rooms`
-   `total_bedrooms`
-   `population`
-   `median_income`
-   `ocean_proximity`

Interpret the coefficients and summarize your results.

```{r}
lm_fit <- lm(median_house_value ~ latitude + longitude + housing_median_age + 
               total_rooms + total_bedrooms + population + median_income + ocean_proximity, data = df_train) # Insert your code here
summary(lm_fit) # Insert your code here
```

------------------------------------------------------------------------

###### 1.5 (5 points)

Complete the `rmse` function for computing the Root Mean-Squared Error
between the true `y` and the predicted `yhat`, and use it to compute the
RMSE for the regression model on `df_test`

```{r}
rmse <- function(y, yhat) {
  sqrt(mean((y - yhat)^2))
}

lm_predictions <- predict(lm_fit, newdata = df_test)
rmse(df_test$median_house_value, lm_predictions) # Insert your code here
```

###### 1.6 (5 points)

Fit a decision tree model to predict the `median_house_value` using the
same predictors as in 1.4. Use the `rpart()` function.

```{r}
rpart_fit <- rpart(median_house_value ~ latitude + longitude + housing_median_age +
                     total_rooms + total_bedrooms + population + median_income + ocean_proximity, 
                   data = df_train) # Insert your code here
rpart_predictions <- predict(rpart_fit, newdata = df_test) # Insert your code here
```

Visualize the decision tree using the `rpart.plot()` function.

```{r}
rpart.plot(rpart_fit) # Insert your code here
```

Report the root mean squared error on the test set.

```{r}
rpart_predictions <- predict(rpart_fit, newdata = df_test)
rmse(df_test$median_house_value, rpart_predictions) # Insert your code here
```

------------------------------------------------------------------------

###### 1.7 (5 points)

Fit a support vector machine model to predict the `median_house_value`
using the same predictors as in 1.4. Use the `svm()` function and use
any kernel of your choice. Report the root mean squared error on the
test set.

```{r}
svm_fit <- svm(median_house_value ~ latitude + longitude + housing_median_age + 
                  total_rooms + total_bedrooms + population + median_income + ocean_proximity, 
                data = df_train, kernel = "radial") # Insert your code here
svm_predictions <- predict(svm_fit, newdata = df_test) # Insert your code here

rmse(df_test$median_house_value, svm_predictions)
```

------------------------------------------------------------------------

###### 1.8 (25 points)

Initialize a neural network model architecture:

```{r}
library(luz)
NNet <- nn_module(
  initialize = function(p, q1, q2, q3){
      weights <- list(
      W1 = torch_randn(q1, p),
      W2 = torch_randn(q2, q1),
      W3 = torch_randn(q3, q2)
    )
    biases <- list(
      b1 = torch_randn(q1),
      b2 = torch_randn(q2),
      b3 = torch_randn(q3)
    )
    return(list(weights = weights, biases = biases))
  },
  forward = function(x){
    W1 <- self$weights$W1
    W2 <- self$weights$W2
    W3 <- self$weights$W3
    b1 <- self$biases$b1
    b2 <- self$biases$b2
    b3 <- self$biases$b3
    
    z1 <- torch_addmm(b1, x, torch_t(W1))
    a1 <- torch_relu(z1)
    z2 <- torch_addmm(b2, a1, torch_t(W2))
    a2 <- torch_relu(z2)
    z3 <- torch_addmm(b3, a2, torch_t(W3))
    
    return(z3)
  }
)



```

Fit a neural network model to predict the `median_house_value` using the
same predictors as in 1.4. Use the `model.matrix` function to create the
covariate matrix and `luz` package for fitting the network with
$32, 16, 8$ nodes in each of the three hidden layers.

```{r}
covariate_matrix <- model.matrix(median_house_value ~ latitude + longitude + housing_median_age +
                                  total_rooms + total_bedrooms + population + median_income + ocean_proximity, 
                                data = df_train)
target <- df_train$median_house_value

# Define optimizer
#optimizer <- optim_adam(lr = 0.001, params = NNet$weights)

# Fit neural network model
#nnet_fit <- NNet %>% 
#  setup(loss = nn_mse_loss(), optimizer = optimizer) %>%
#  set_hparams(
 #   p = ncol(covariate_matrix),  # Number of input features
  #  q1 = 32,
   # q2 = 16,
    #q3 = 8
#  ) %>%
 # train(
  #  covariate_matrix,
   # target,
  #  dataloader_options = list(shuffle = TRUE),
   # verbose = FALSE
  #)
```

Plot the results of the training and validation loss and accuracy.

``` r
... # Insert your code here
```

Report the root mean squared error on the test set.

``` r
nnet_predictions <- ... # Insert your code here
```

::: callout-warning
Remember to use the `as_array()` function to convert the predictions to
a vector of numbers before computing the RMSE with `rmse()`
:::

------------------------------------------------------------------------

###### 1.9 (5 points)

Summarize your results in a table comparing the RMSE for the different
models. Which model performed best? Why do you think that is?

```{r}
lm_rmse <- rmse(df_test$median_house_value, lm_predictions)
rpart_rmse <- rmse(df_test$median_house_value, rpart_predictions)
svm_rmse <- rmse(df_test$median_house_value, svm_predictions)

results <- data.frame(
  Model = c("Linear Regression", "Decision Tree", "Support Vector Machine"),
  RMSE = c(lm_rmse, rpart_rmse, svm_rmse)
)

print(results)
 # Insert your code here

print("Decision tree worked the best")
```

<br><br><br><br> <br><br><br><br> ---

## Question 2

::: callout-tip
## 50 points

Spam email classification
:::

The `data` folder contains the `spam.csv` dataset. This dataset contains
features extracted from a collection of spam and non-spam emails. The
objective is to classify the emails as spam or non-spam.

------------------------------------------------------------------------

###### 2.1 (2.5 points)

Read the data file as a tibble in R. Preprocess the data such that:

1.  the variables are of the right data type, e.g., categorical
    variables are encoded as factors
2.  all column names to lower case for consistency
3.  Any observations with missing values are dropped

```{r}
df <- read_csv("data/spambase.csv")

# Preprocess the data
df <- df %>%
  # Convert categorical variables to factors
  mutate_if(is.character, as.factor) %>%
  # Convert column names to lower case
  rename_all(tolower) %>%
  # Drop observations with missing values
  drop_na()

# View the resulting tibble
print(df) # Insert your code here
```

------------------------------------------------------------------------

###### 2.2 (2.5 points)

Split the data `df` into `df_train` and `df_split` using `test_ind` in
the code below:

```{r}
set.seed(42)
test_ind <- sample(
  1:nrow(df), 
  floor( nrow(df)/10 ),
  replace=FALSE
)

df_train <- df[-test_ind, ] # Insert your code here
df_test  <- df[test_ind, ] # Insert your code here
```

Complete the `overview` function which returns a data frame with the
following columns: `accuracy`, `error`, `false positive rate`,
`true positive rate`, between the true `true_class` and the predicted
`pred_class` for any classification model.

```{r}
overview <- function(pred_class, true_class) {
  accuracy <- mean(pred_class == true_class) # Insert your code here
  error <- 1 - accuracy # Insert your code here
  true_positives <- sum(pred_class == true_class & pred_class == 1) # Insert your code here
  true_negatives <- sum(pred_class == true_class & pred_class == 0) # Insert your code here
  false_positives <- sum(pred_class != true_class & pred_class == 1) # Insert your code here
  false_negatives <- sum(pred_class != true_class & pred_class == 0) # Insert your code here
  true_positive_rate <- true_positives / sum(true_class == 1) # Insert your code here
  false_positive_rate <- false_positives / sum(true_class == 0)  # Insert your code here
  return(
    data.frame(
      accuracy = accuracy,
      error = error,
      true_positive_rate = true_positive_rate,
      false_positive_rate = false_positive_rate
    )
  )
}
```

------------------------------------------------------------------------

###### 2.3 (5 points)

Fit a logistic regression model to predict the `spam` variable using the
remaining predictors. Report the prediction accuracy on the test set.

```{r}
glm_fit <- glm(spam ~ ., data = df_train, family = binomial) # Insert your code here
glm_classes <- predict(glm_fit, newdata = df_test, type = "response") > 0.5 # Insert your code here

accuracy <- mean(glm_classes == df_test$spam)
accuracy
```

------------------------------------------------------------------------

###### 2.4 (5 points)

Fit a decision tree model to predict the `spam` variable using the
remaining predictors. Use the `rpart()` function and set the `method`
argument to `"class"`.

```{r}
rpart_model <- rpart(spam ~ ., data = df_train, method = "class")
rpart_classes <- predict(rpart_model, newdata = df_test, type = "class") # Insert your code here
```

Visualize the decision tree using the `rpart.plot()` function.

```{r}
rpart.plot(rpart_model) # Insert your code here
```

Report the prediction accuracy on the test set.

```{r}
mean(rpart_classes == df_test$spam) # Insert your code here
```

------------------------------------------------------------------------

###### 2.5 (5 points)

Fit a support vector machine model to predict the `spam` variable using
the remaining predictors. Use the `svm()` function and use any kernel of
your choice. Remember to set the `type` argument to `"C-classification"`
**if you haven't** already converted `spam` to be of type `factor`.

```{r}
svm_fit <- svm(spam ~ ., data = df_train, type = "C-classification", kernel = "radial") # Insert your code here
```

Report the prediction accuracy on the test set.

```{r}
svm_classes <- predict(svm_fit, newdata = df_test) # Insert your code here
mean(svm_classes == df_test$spam)
```

------------------------------------------------------------------------

###### 2.6 (25 points)

Using the same neural network architecture as in 1.9, fit a neural
network model to predict the `spam` variable using the remaining
predictors.

::: callout-warning
## Classification vs. Regression

Note that the neural network in **Q 1.9** was a regression model. You
will need to modify the neural network architecture to be a
classification model by changing the output layer to have a single node
with a sigmoid activation function.
:::

Use the `model.matrix` function to create the covariate matrix and `luz`
package for fitting the network with $32, 16, 8$ nodes in each of the
three hidden layers.

```{r}
# Modify the neural network architecture for classification
NNet <- nn_module(
  initialize = function(p, q1, q2, q3){
    weights <- list(
      W1 = torch_randn(q1, p),
      W2 = torch_randn(q2, q1),
      W3 = torch_randn(q3, q2),
      W_out = torch_randn(1, q3)  # Output layer with single node
    )
    biases <- list(
      b1 = torch_randn(q1),
      b2 = torch_randn(q2),
      b3 = torch_randn(q3),
      b_out = torch_randn(1)  # Bias for the output layer
    )
    return(list(weights = weights, biases = biases))
  },
  forward = function(x){
    W1 <- self$weights$W1
    W2 <- self$weights$W2
    W3 <- self$weights$W3
    W_out <- self$weights$W_out  # Output layer weights

    b1 <- self$biases$b1
    b2 <- self$biases$b2
    b3 <- self$biases$b3
    b_out <- self$biases$b_out  # Bias for the output layer
    
    z1 <- torch_addmm(b1, x, torch_t(W1))
    a1 <- torch_relu(z1)
    z2 <- torch_addmm(b2, a1, torch_t(W2))
    a2 <- torch_relu(z2)
    z3 <- torch_addmm(b3, a2, torch_t(W3))
    a3 <- torch_relu(z3)
    
    # Output layer with sigmoid activation function
    logits <- torch_addmm(b_out, a3, torch_t(W_out))
    output <- torch_sigmoid(logits)
    
    return(output)
  }
)
covariate_matrix <- model.matrix(spam ~ ., data = df_train)[,-1]  # Exclude intercept column
target <- ifelse(df_train$spam == "spam", 1, 0)

#nnet_fit <- NNet %>% 
 # setup(
  #  loss = nn_bce_loss(), optimizer = optim_adam(lr = 0.001) # Insert your code here
#  ) %>%
 # set_hparams(
  #  p = ncol(covariate_matrix),  # Number of input features
   # q1 = 32,
  #  q2 = 16,
   # q3 = 8 # Insert your code here
#  ) %>%
 # fit(
  #  covariate_matrix,
   # target, # Insert your code here
  #  dataloader_options = list(shuffle = TRUE),# Insert your code here
   # verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting

  #)
```

------------------------------------------------------------------------

###### 2.7 (5 points)

Summarize your results in a table comparing the accuracy metrics for the
different models.

```{r}
# Calculate accuracy for each model
accuracy_logistic <- mean(glm_classes == df_test$spam)
accuracy_decision_tree <- mean(rpart_classes == df_test$spam)
accuracy_svm <- mean(svm_classes == df_test$spam)
#accuracy_neural_network <- accuracy(nnet_fit)

# Create a data frame for the results
results <- data.frame(
  Model = c("Logistic Regression", "Decision Tree", "SVM"), #"Neural Network"),
  Accuracy = c(accuracy_logistic, accuracy_decision_tree, accuracy_svm) #, accuracy_neural_network)
)

# Print the results
print(results) # Insert your code here
```

If you were to choose a model to classify spam emails, which model would
you choose? Think about the context of the problem and the cost of false
positives and false negatives.

```{r}
print("I would choose logistic regression")

```

<br><br><br><br> <br><br><br><br> ---

## Question 3

::: callout-tip
## 60 points

Three spirals classification
:::

To better illustrate the power of depth in neural networks, we will use
a toy dataset called the "Three Spirals" data. This dataset consists of
two intertwined spirals, making it challenging for shallow models to
classify the data accurately.

::: callout-warning
## This is a multi-class classification problem
:::

The dataset can be generated using the provided R code below:

```{R}
generate_three_spirals <- function(){
  set.seed(42)
  n <- 500
  noise <- 0.2
  t <- (1:n) / n * 2 * pi
  x1 <- c(
      t * (sin(t) + rnorm(n, 0, noise)),
      t * (sin(t + 2 * pi/3) + rnorm(n, 0, noise)),
      t * (sin(t + 4 * pi/3) + rnorm(n, 0, noise))
    )
  x2 <- c(
      t * (cos(t) + rnorm(n, 0, noise)),
      t * (cos(t + 2 * pi/3) + rnorm(n, 0, noise)),
      t * (cos(t + 4 * pi/3) + rnorm(n, 0, noise))
    )
  y <- as.factor(
    c(
      rep(0, n), 
      rep(1, n), 
      rep(2, n)
    )
  )
  return(tibble::tibble(x1=x1, x2=x2, y=y))
}
```

------------------------------------------------------------------------

###### 3.1 (5 points)

Generate the three spirals dataset using the code above. Plot $x_1$ vs
$x_2$ and use the `y` variable to color the points.

```{R}
df <- generate_three_spirals()

plot(
  df$x1, df$x2,
  col = df$y,
  pch = 20
)
```

Define a grid of $100$ points from $-10$ to $10$ in both $x_1$ and $x_2$
using the `expand.grid()`. Save it as a tibble called `df_test`.

```{r}
grid <- expand.grid(
  x1 = seq(-10, 10, length.out = 10),
  x2 = seq(-10, 10, length.out = 10)
) # Insert your code here
df_test <- as_tibble(grid) # Insert your code here
```

------------------------------------------------------------------------

###### 3.2 (10 points)

Fit a classification tree model to predict the `y` variable using the
`x1` and `x2` predictors, and plot the decision boundary.

``` {r}
rpart_fit <- rpart(y ~ x1 + x2, data = df, method = "class") # Insert your code here
rpart_classes <- predict(rpart_fit, newdata = df_test, type = "class") # Insert your code here
```

Plot the decision boundary using the following function:

``` {r}
plot_decision_boundary <- function(predictions){
  plot(
    df_test$x1, df_test$x2, 
    col = predictions,
    pch = 0
  )
  points(
    df$x1, df$x2,
    col = df$y,
    pch = 20
  )
}
```

``` {r}
plot_decision_boundary(rpart_classes)
```

------------------------------------------------------------------------

###### 3.3 (10 points)

Fit a support vector machine model to predict the `y` variable using the
`x1` and `x2` predictors. Use the `svm()` function and use any kernel of
your choice. Remember to set the `type` argument to `"C-classification"`
**if you haven't** converted `y` to be of type `factor`.

``` {r}
svm_fit <- svm(y ~ x1 + x2, data = df, type = "C-classification", kernel = "radial")# Insert your code here
svm_classes <- predict(svm_fit, newdata = df_test) # Insert your code here
plot_decision_boundary(svm_classes)
```

------------------------------------------------------------------------

::: callout-warning
## Instructions

For the next questions, you will need to fit a series of neural
networks. In all cases, you can:

-   set the number of units in each hidden layer to 10
-   set the output dimension `o` to 3 (remember this is multinomial
    classification)
-   use the appropriate loss function for the problem (**not
    `nn_bce_loss`**)
-   set the number of epochs to $50$
-   fit the model using the `luz` package

You can use any optimizer of your choice, but you **will need to tune
the learning rate for each problem**.
:::

###### 3.4 (10 points)

Fit a neural network with **1 hidden layer** to predict the `y` variable
using the `x1` and `x2` predictors.

``` {r}
NN1 <- nn_module(
  initialize = function(p, q1, o){
    self$hidden1 <- nn_linear(p, q1) # Insert your code here
    self$output <- nn_linear(q1, o) # Insert your code here
    self$activation <- nn_relu() # Insert your code here
  },
  forward = function(x){
    x %>% 
      self$hidden1() %>% 
      self$activation() %>% 
      self$output()
  }
)

#fit_1 <- NN1 %>% 
 # setup(
  #  p = 2,  # Number of input features (x1, x2)
   # q1 = 10,  # Number of units in the hidden layer
    #o = 3  # Insert your code here
#  ) %>%
 # set_hparams(
  #  loss_fn = nn_cross_entropy_loss(),  
   # epochs = 50 # Insert your code here
#  ) %>%
 # fit(
  #  data = list(
   ##   df %>% select(x1, x2) %>% as.matrix,
     # df$y %>% as.integer
  #  ),
    # Insert your code here
   # dataloader_options = list(batch_size = 32), # Insert your code here
    #verbose = FALSE
  #)
```

In order to generate the class predictions, you will need to use the
`predict()` function as follows

``` {r}
test_matrix <- df_test %>% select(x1, x2) %>% as.matrix

#fit_1_predictions <- predict(fit_1, test_matrix) %>% 
 # argmax(2) %>% 
#  as.integer()
```

Plot the results using the `plot_decision_boundary()` function.

------------------------------------------------------------------------

###### 3.5 (10 points)

Fit a neural network with **0 hidden layers** to predict the `y`
variable using the `x1` and `x2` predictors.

``` {r}
NN0 <- nn_module(
  initialize = function(p, o){
    self$output <- nn_linear(p, o) # Insert your code here
  },
  forward = function(x){
    x %>% 
      self$output() # Insert your code here
  }
)

#fit_0 <- NN0 %>% 
 # setup(p = 2,  
  #  o = 3) %>%
#  set_hparams(loss_fn = nn_cross_entropy_loss(),  
 #   epochs = 50) %>%
#  set_opt_hparams(lr = 0.01) %>%
 # fit(ata = list(
  #    x = df_train %>% select(x1, x2) %>% as.matrix(),
   #   y = df_train$y %>% as.integer()
  #  ),
   # dataloader_options = list(batch_size = 32),
   # verbose = FALSE)
```

Plot the results using the `plot_decision_boundary()` function.

------------------------------------------------------------------------

###### 3.6 (10 points)

Fit a neural network with **3 hidden layers** to predict the `y`
variable using the `x1` and `x2` predictors.

``` {r}
NN2 <- nn_module(
  initialize = function(p, q1, q2, o){
    self$hidden1 <- nn_linear(p, q1)
    self$hidden2 <- nn_linear(q1, q2)
    self$hidden3 <- nn_linear(q2, q2)
    self$output <- nn_linear(q2, o)
    self$activation <- nn_relu() # Insert your code here
  },
  forward = function(x){
    x %>% 
      self$hidden1() %>% 
      self$activation() %>% 
      self$hidden2() %>% 
      self$activation() %>% 
      self$hidden3() %>% 
      self$activation() %>% 
      self$output() # Insert your code here
  }
)

#fit_2 <- NN3 %>% 
#  setup(p = 2,  # Number of input features (x1, x2)
 #   q1 = 10,  # Number of units in the first hidden layer
  #  q2 = 10,  # Number of units in the second and third hidden layers
   # o = 3  ) %>%
#  set_hparams(loss_fn = nn_cross_entropy_loss(),  # Cross-entropy loss for multinomial classification
 #   epochs = 50) %>%
#  fit(data = list(
 #     x = df_train %>% select(x1, x2) %>% as.matrix(),
  #    y = df_train$y %>% as.integer()
  #  ),
   # dataloader_options = list(batch_size = 32),
  #  verbose = FALSE)
```

Plot the results using the `plot_decision_boundary()` function.

------------------------------------------------------------------------

###### 3.7 (5 points)

What are the differences between the models? How do the decision
boundaries change as the number of hidden layers increases?
```{r}
print("As the number of hidden layers increases in neural network models, 
      their capacity to learn complex patterns from the data improves, 
      resulting in decision boundaries that are more flexible and 
      capable of capturing intricate relationships between features, 
      whereas models with fewer hidden layers or none are
      limited to simpler decision boundaries.")

```

------------------------------------------------------------------------

::: {.hidden unless-format="pdf"}
\pagebreak
:::

<br><br><br><br> <br><br><br><br> ---

::: {.callout-note collapse="true"}
## Session Information

Print your `R` session information using the following command

```{R}
sessionInfo()
```
:::
